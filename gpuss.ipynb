{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14392697,"sourceType":"datasetVersion","datasetId":9191956}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\n# ==============================================================================\n# GPU SERVER - FIREBASE EDITION (V2.4 - DATASET CREDENTIAL LOADER)\n# VERSION: 2.4 - PARALLEL GPU CORES + DATASET AUTO-LOADER\n# ==============================================================================\nimport subprocess\nimport sys\nimport os\nimport time\nimport uuid\nimport threading\nimport json\nimport random\nimport math\nimport urllib.request\nimport logging\nimport shutil\nimport glob\nfrom datetime import datetime, timedelta, timezone\n\n# ============================================================================\n# CRITICAL: CHANGE THIS FOR EACH GPU SERVER\n# ============================================================================\nSERVER_ID = \"server_1\"  # â† Change to: server_1, server_2, server_3, or server_4\n# ============================================================================\n\n# DATASET CONFIGURATION\nCREDENTIALS_DATASET = \"firebase-credentials\"  # â† Same dataset as CPU bot\n\n# Optimize Memory\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\n\n# ------------------------------------------\n# CONFIGURATION\n# ------------------------------------------\nR2_ACCOUNT_ID = \"4fa19e788a951ba2d879c18782ef8bf0\"\nR2_ACCESS_KEY_ID = \"d66adcff67ac5b4eca609a662b80e742\"\nR2_SECRET_ACCESS_KEY = \"1a10aca3049c176d85cf3ec3c4e4ae8c6b715a4d9b1e67a79acc8b94d3b3c660\"\nR2_BUCKET_NAME = \"video-generation-storage\"\nR2_ENDPOINT_URL = f\"https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com\"\n\n# FIREBASE DATABASE URL (will auto-detect from credentials)\nFIREBASE_DATABASE_URL = None  # Will be set after loading credentials\n\n# ------------------------------------------\n# DEPENDENCY CHECK\n# ------------------------------------------\ndef install_if_missing(package, import_name=None):\n    if import_name is None:\n        import_name = package\n    try:\n        __import__(import_name)\n    except ImportError:\n        print(f\"â¬‡ï¸ Installing {package}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n\nif shutil.which('ffmpeg') is None:\n    print(\"Installing FFmpeg...\")\n    subprocess.run([\"apt-get\", \"update\"], stdout=subprocess.DEVNULL)\n    subprocess.run([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"], stdout=subprocess.DEVNULL)\n\ninstall_if_missing(\"boto3\")\ninstall_if_missing(\"firebase-admin\", \"firebase_admin\")\ninstall_if_missing(\"openai-whisper\", \"whisper\")\ninstall_if_missing(\"moviepy\")\ninstall_if_missing(\"unidecode\")\ninstall_if_missing(\"Pillow\", \"PIL\")\n\ntry:\n    import diffusers\n    import transformers\n    import accelerate\nexcept ImportError:\n    print(\"â¬‡ï¸ Installing AI Libraries...\")\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"diffusers\", \"transformers\", \"accelerate\", \"safetensors\", \"xformers\"])\n\n# ------------------------------------------\n# IMPORTS\n# ------------------------------------------\nimport torch\nfrom diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler, AutoencoderKL\nimport boto3\nfrom botocore.config import Config\nimport firebase_admin\nfrom firebase_admin import credentials, db\nimport whisper\nfrom PIL import Image, ImageFont, ImageDraw\n\n# ==============================================================================\n# FIREBASE CREDENTIAL AUTO-LOADER FROM KAGGLE DATASET\n# ==============================================================================\n\ndef load_firebase_credentials_from_dataset():\n    \"\"\"\n    Automatically loads ALL Firebase JSON credential files from Kaggle dataset.\n    Returns list of config dictionaries with auto-failover support.\n    \"\"\"\n    configs = []\n    dataset_path = f\"/kaggle/input/{CREDENTIALS_DATASET}\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"ğŸ” [{SERVER_ID}] LOADING FIREBASE CREDENTIALS FROM DATASET\")\n    print(\"=\"*70)\n    print(f\"ğŸ“ Dataset: {CREDENTIALS_DATASET}\")\n    print(f\"ğŸ“‚ Path: {dataset_path}\\n\")\n    \n    # Check if dataset exists\n    if not os.path.exists(dataset_path):\n        print(f\"âš ï¸  Dataset not found: {dataset_path}\")\n        print(\"\\nğŸ’¡ SETUP INSTRUCTIONS:\")\n        print(\"   Make sure you added the firebase-credentials dataset to this notebook!\")\n        print(\"   (Should be the same dataset as CPU bot)\")\n        return []\n    \n    # Find all JSON files\n    json_files = glob.glob(f\"{dataset_path}/*.json\")\n    \n    if not json_files:\n        print(f\"âš ï¸  No .json files found in {dataset_path}\")\n        return []\n    \n    print(f\"âœ… Found {len(json_files)} credential file(s):\\n\")\n    \n    # Load each file\n    for json_file in sorted(json_files):\n        try:\n            with open(json_file, 'r') as f:\n                cred_data = json.load(f)\n            \n            # Validate required fields\n            if 'project_id' not in cred_data or 'private_key' not in cred_data:\n                print(f\"  âš ï¸  Skipping {os.path.basename(json_file)}: Missing required fields\")\n                continue\n            \n            # Build database URL from project_id\n            project_id = cred_data['project_id']\n            database_url = f\"https://{project_id}-default-rtdb.firebaseio.com\"\n            \n            configs.append({\n                'name': os.path.basename(json_file),\n                'url': database_url,\n                'cred': cred_data,\n                'project_id': project_id\n            })\n            \n            print(f\"  âœ… {os.path.basename(json_file)}\")\n            print(f\"     ğŸ“Œ Project: {project_id}\")\n            \n        except json.JSONDecodeError:\n            print(f\"  âŒ Invalid JSON: {os.path.basename(json_file)}\")\n        except Exception as e:\n            print(f\"  âŒ Error: {os.path.basename(json_file)} - {e}\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"ğŸ“Š Total valid credentials: {len(configs)}\")\n    print(\"=\"*70 + \"\\n\")\n    \n    return configs\n\ndef initialize_firebase_with_failover(configs):\n    \"\"\"\n    Tries each credential until one works (auto-failover).\n    Returns True if connected, False otherwise.\n    \"\"\"\n    global FIREBASE_DATABASE_URL\n    \n    if not configs:\n        print(\"âš ï¸  No credentials available to try!\")\n        return False\n    \n    print(\"=\"*70)\n    print(f\"ğŸ”§ [{SERVER_ID}] CONNECTING TO FIREBASE (AUTO-FAILOVER)\")\n    print(\"=\"*70 + \"\\n\")\n    \n    for idx, config in enumerate(configs, 1):\n        print(f\"[Attempt {idx}/{len(configs)}] Trying: {config['name']}\")\n        print(f\"  ğŸ“Œ Project: {config['project_id']}\")\n        \n        try:\n            # Check if already initialized\n            try:\n                app = firebase_admin.get_app()\n                print(f\"  âœ… Firebase already initialized (reusing connection)\")\n                FIREBASE_DATABASE_URL = config['url']\n                return True\n            except ValueError:\n                pass  # Not initialized yet, proceed\n            \n            # Try to initialize with this credential\n            cred = credentials.Certificate(config['cred'])\n            firebase_admin.initialize_app(cred, {\n                'databaseURL': config['url']\n            })\n            \n            # Test connection\n            test_ref = db.reference(f'/servers/{SERVER_ID}/heartbeat')\n            test_ref.set({\n                'timestamp': time.time(),\n                'status': 'initializing',\n                'server_id': SERVER_ID\n            })\n            \n            FIREBASE_DATABASE_URL = config['url']\n            \n            print(f\"  âœ… CONNECTION SUCCESSFUL!\")\n            print(f\"  ğŸ‰ Using credential: {config['name']}\")\n            print(f\"  ğŸŒ Database: {config['url']}\\n\")\n            return True\n            \n        except Exception as e:\n            error_msg = str(e)\n            if len(error_msg) > 150:\n                error_msg = error_msg[:150] + \"...\"\n            print(f\"  âŒ Failed: {error_msg}\")\n            \n            # Clean up failed attempt\n            try:\n                app = firebase_admin.get_app()\n                firebase_admin.delete_app(app)\n            except:\n                pass\n            \n            if idx < len(configs):\n                print(f\"  ğŸ”„ Trying next credential...\\n\")\n            else:\n                print(f\"  âš ï¸  No more credentials to try\\n\")\n    \n    return False\n\n# ==============================================================================\n# FIREBASE INITIALIZATION\n# ==============================================================================\nprint(\"\\n\" + \"=\"*70)\nprint(f\"ğŸš€ [{SERVER_ID}] FIREBASE INITIALIZATION STARTING...\")\nprint(\"=\"*70 + \"\\n\")\n\n# Load credentials from dataset\nFIREBASE_CONFIGS = load_firebase_credentials_from_dataset()\n\nif FIREBASE_CONFIGS:\n    # Use dataset credentials with failover\n    success = initialize_firebase_with_failover(FIREBASE_CONFIGS)\n    \n    if not success:\n        print(\"\\n\" + \"=\"*70)\n        print(f\"âŒ [{SERVER_ID}] ALL DATASET CREDENTIALS FAILED!\")\n        print(\"=\"*70)\n        print(\"\\nâš ï¸  TROUBLESHOOTING:\")\n        print(\"  1. Check if credentials are revoked in Firebase Console\")\n        print(\"  2. Verify dataset is properly added to this notebook\")\n        print(\"  3. Check if dataset contains valid JSON files\")\n        print(\"\\n\")\n        sys.exit(1)\nelse:\n    print(\"\\n\" + \"=\"*70)\n    print(f\"âŒ [{SERVER_ID}] NO CREDENTIALS FOUND!\")\n    print(\"=\"*70)\n    print(\"\\nâš ï¸  Make sure you added the firebase-credentials dataset!\")\n    print(\"\\n\")\n    sys.exit(1)\n\nprint(\"=\"*70)\nprint(f\"âœ… [{SERVER_ID}] FIREBASE READY!\")\nprint(\"=\"*70 + \"\\n\")\n\n# ------------------------------------------\n# FONT MANAGEMENT\n# ------------------------------------------\nFONT_DIR = \"./fonts\"\nSUBTITLE_FONTS = {}\n\nFONT_CONFIG = {\n    'latin': {'file': 'NotoSans-Bold.ttf', 'url': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSans/hinted/ttf/NotoSans-Bold.ttf', 'family_name': 'Noto Sans', 'weight': 'Bold'},\n    'devanagari': {'file': 'NotoSansDevanagari-Bold.ttf', 'url': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansDevanagari/hinted/ttf/NotoSansDevanagari-Bold.ttf', 'family_name': 'Noto Sans Devanagari', 'weight': 'Bold'},\n    'arabic': {'file': 'NotoSansArabic-Bold.ttf', 'url': 'https://github.com/notofonts/notofonts.github.io/raw/main/fonts/NotoSansArabic/hinted/ttf/NotoSansArabic-Bold.ttf', 'family_name': 'Noto Sans Arabic', 'weight': 'Bold'},\n    'cjk': {'file': 'NotoSansCJKsc-Bold.otf', 'url': 'https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Bold.otf', 'family_name': 'Noto Sans CJK SC', 'weight': 'Bold'}\n}\n\ndef setup_fonts():\n    if not os.path.exists(FONT_DIR):\n        os.makedirs(FONT_DIR)\n    print(\"â¬‡ï¸ Setting up fonts...\")\n    for script, config in FONT_CONFIG.items():\n        path = os.path.join(FONT_DIR, config['file'])\n        if not os.path.exists(path):\n            try:\n                urllib.request.urlretrieve(config['url'], path)\n            except Exception as e:\n                print(f\"âŒ Font download failed ({script}): {e}\")\n                continue\n        if os.path.exists(path):\n            SUBTITLE_FONTS[script] = path\n\nsetup_fonts()\n\n# ------------------------------------------\n# SUBTITLE ENGINE\n# ------------------------------------------\ndef detect_script(text):\n    if not text or not text.strip(): return 'latin'\n    counts = {'devanagari': 0, 'arabic': 0, 'cjk': 0, 'latin': 0}\n    for char in text:\n        code = ord(char)\n        if 0x0900 <= code <= 0x0DFF: counts['devanagari'] += 1\n        elif 0x0600 <= code <= 0x077F: counts['arabic'] += 1\n        elif 0x4E00 <= code <= 0x9FFF or 0x3040 <= code <= 0x30FF: counts['cjk'] += 1\n        else: counts['latin'] += 1\n    max_script = max(counts.items(), key=lambda x: x[1])\n    return max_script[0] if max_script[1] > 0 else 'latin'\n\ndef get_font_for_text(text):\n    script = detect_script(text)\n    mapping = {'devanagari': 'devanagari', 'arabic': 'arabic', 'cjk': 'cjk'}\n    key = mapping.get(script, 'latin')\n    if key in SUBTITLE_FONTS:\n        return SUBTITLE_FONTS[key], FONT_CONFIG[key], script\n    return SUBTITLE_FONTS.get('latin'), FONT_CONFIG.get('latin'), 'latin'\n\ndef time_to_ass(seconds):\n    h = int(seconds // 3600)\n    m = int((seconds % 3600) // 60)\n    s = int(seconds % 60)\n    cs = int((seconds % 1) * 100)\n    return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n\ndef calculate_text_width(text, font_path, font_size):\n    try:\n        font = ImageFont.truetype(font_path, font_size)\n        dummy = ImageDraw.Draw(Image.new(\"RGBA\", (1, 1)))\n        bbox = dummy.textbbox((0, 0), text, font=font)\n        return bbox[2] - bbox[0]\n    except:\n        return len(text) * font_size * 0.6\n\ndef create_ass_event_for_page(page_lines, font_size, events, is_cjk, is_latin):\n    if not page_lines: return\n    start_time = page_lines[0][0]['start']\n    end_time = page_lines[-1][-1]['end']\n    \n    def process_word(word_obj):\n        raw = word_obj.get('word', '').strip()\n        return raw.upper() if is_latin else raw\n    \n    separator = '' if is_cjk else ' '\n    full_text_lines = [separator.join([process_word(w) for w in line]) for line in page_lines]\n    full_text = '\\\\N'.join(full_text_lines)\n    \n    events.append(f\"Dialogue: 0,{time_to_ass(start_time)},{time_to_ass(end_time)},BG,,0,0,0,,{{\\\\bord15\\\\shad0\\\\1c&H000000&\\\\1a&H4D&}}{full_text}\")\n    \n    for line_idx, line in enumerate(page_lines):\n        for word_idx, word_obj in enumerate(line):\n            w_start = word_obj.get('start', start_time)\n            w_end = word_obj.get('end', end_time)\n            highlight_lines = []\n            for l_idx, l in enumerate(page_lines):\n                line_words = []\n                for w_idx, w in enumerate(l):\n                    disp = process_word(w)\n                    if l_idx == line_idx and w_idx == word_idx:\n                        line_words.append(f\"{{\\\\bord8\\\\3c&HD30093&\\\\3a&H4D&\\\\shad2\\\\4c&H000000&\\\\4a&H00&}}{disp}{{\\\\bord0\\\\shad0}}\")\n                    else:\n                        line_words.append(disp)\n                highlight_lines.append(separator.join(line_words))\n            hl_text = '\\\\N'.join(highlight_lines)\n            events.append(f\"Dialogue: 1,{time_to_ass(w_start)},{time_to_ass(w_end)},PurpleBG,,0,0,0,,{hl_text}\")\n    \n    events.append(f\"Dialogue: 2,{time_to_ass(start_time)},{time_to_ass(end_time)},Default,,0,0,0,,{full_text}\")\n    \n    for line_idx, line in enumerate(page_lines):\n        for word_idx, word_obj in enumerate(line):\n            w_start = word_obj.get('start', start_time)\n            w_end = word_obj.get('end', end_time)\n            top_lines = []\n            for l_idx, l in enumerate(page_lines):\n                line_words = []\n                for w_idx, w in enumerate(l):\n                    disp = process_word(w)\n                    if l_idx == line_idx and w_idx == word_idx:\n                        line_words.append(f\"{{\\\\c&HFFFFFF&}}{disp}\")\n                    else:\n                        line_words.append(disp)\n                top_lines.append(separator.join(line_words))\n            joined_top_lines = '\\\\N'.join(top_lines)\n            events.append(f\"Dialogue: 3,{time_to_ass(w_start)},{time_to_ass(w_end)},Default,,0,0,0,,{joined_top_lines}\")\n\ndef generate_clip_ass_subtitles(subtitle_words, width, height, output_file):\n    if not subtitle_words: return False\n    \n    all_text_raw = \"\".join([w.get('word', '') for w in subtitle_words])\n    font_path, font_config, script = get_font_for_text(all_text_raw)\n    font_family = font_config['family_name']\n    is_cjk = script == 'cjk'\n\n    processed_words = []\n    if is_cjk:\n        for w in subtitle_words:\n            text = w.get('word', '').strip()\n            start = w.get('start', 0)\n            end = w.get('end', 0)\n            duration = end - start\n            length = len(text)\n            if length > 1:\n                char_duration = duration / length\n                for i, char in enumerate(text):\n                    char_start = start + (i * char_duration)\n                    char_end = start + ((i + 1) * char_duration)\n                    processed_words.append({'word': char, 'start': char_start, 'end': char_end})\n            elif length == 1:\n                processed_words.append(w)\n    else:\n        processed_words = subtitle_words\n\n    aspect = width / height\n    if aspect < 0.8:\n        ref_h, ref_f, ref_pos, pos_offset = 1280, 63, 0.75, 0\n    elif aspect > 1.5:\n        ref_h, ref_f, ref_pos, pos_offset = 720, 72, 0.85, 38\n    else:\n        ref_h, ref_f, ref_pos, pos_offset = 1080, 68, 0.80, 0\n        \n    font_size = int(ref_f * (height / ref_h))\n    ref_position = int(height * ref_pos) + pos_offset\n    margin_v = height - ref_position\n    \n    header = f\"\"\"[Script Info]\nScriptType: v4.00+\nPlayResX: {width}\nPlayResY: {height}\nWrapStyle: 0\nScaledBorderAndShadow: yes\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,{font_family},{font_size},&H00FFFFFF,&H000000FF,&H00000000,&HB3000000,-1,0,0,0,100,100,0,0,1,0,0,2,20,20,{margin_v},1\nStyle: BG,{font_family},{font_size},&H00FFFFFF,&H000000FF,&H00000000,&HB3000000,-1,0,0,0,100,100,0,0,1,0,0,2,20,20,{margin_v},1\nStyle: PurpleBG,{font_family},{font_size},&H00FFFFFF,&H000000FF,&H00000000,&HB4D30093,-1,0,0,0,100,100,0,0,1,3,2,2,20,20,{margin_v},1\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n\"\"\"\n    events = []\n    is_latin = script == 'latin'\n    max_line_width = width * 0.90\n    space_width = 0 if is_cjk else int(font_size * 0.25)\n    \n    current_page_lines = []\n    current_line = []\n    current_line_width = 0\n    \n    for word_obj in processed_words:\n        raw = word_obj.get('word', '').strip()\n        disp = raw.upper() if is_latin else raw\n        w_width = calculate_text_width(disp, font_path, font_size) + 10\n        \n        if current_line_width + w_width + space_width > max_line_width:\n            if current_line: current_page_lines.append(current_line)\n            if len(current_page_lines) >= 2:\n                create_ass_event_for_page(current_page_lines, font_size, events, is_cjk, is_latin)\n                current_page_lines = []\n            current_line = [word_obj]\n            current_line_width = w_width + space_width\n        else:\n            current_line.append(word_obj)\n            current_line_width += w_width + space_width\n            \n    if current_line: current_page_lines.append(current_line)\n    if current_page_lines: create_ass_event_for_page(current_page_lines, font_size, events, is_cjk, is_latin)\n    \n    with open(output_file, 'w', encoding='utf-8') as f:\n        f.write(header + \"\\n\".join(events))\n    return True\n\n# ------------------------------------------\n# R2 CLIENT\n# ------------------------------------------\nprint(\"ğŸ”§ Setting up R2...\")\ns3_client = boto3.client(\n    's3',\n    endpoint_url=R2_ENDPOINT_URL,\n    aws_access_key_id=R2_ACCESS_KEY_ID,\n    aws_secret_access_key=R2_SECRET_ACCESS_KEY,\n    config=Config(signature_version='s3v4'),\n    region_name='auto'\n)\nprint(\"âœ… R2 ready\")\n\n# ------------------------------------------\n# FIREBASE HEARTBEAT\n# ------------------------------------------\ndef heartbeat_worker():\n    print(f\"ğŸ’“ Heartbeat started for {SERVER_ID}...\")\n    while True:\n        try:\n            db.reference(f'/servers/{SERVER_ID}/heartbeat').set({\n                'timestamp': time.time(),\n                'status': 'active',\n                'server_id': SERVER_ID\n            })\n            time.sleep(5)\n        except Exception as e:\n            print(f\"ğŸ’“ Heartbeat error: {e}\")\n            time.sleep(10)\n\nthreading.Thread(target=heartbeat_worker, daemon=True).start()\n\n# ------------------------------------------\n# WHISPER MODEL\n# ------------------------------------------\nprint(\"â³ Loading Whisper Model on GPU...\")\nWHISPER_MODEL = whisper.load_model(\"base\", device=\"cuda\")\nprint(\"âœ… Whisper model loaded\")\n\n# ------------------------------------------\n# TRANSCRIPTION FUNCTIONS\n# ------------------------------------------\ndef format_time_ref(seconds):\n    m = int(seconds // 60)\n    s = int(seconds % 60)\n    return f\"{m:02d}:{s:02d}\"\n\ndef create_prompts_txt(raw_result, duration):\n    try:\n        from unidecode import unidecode\n        num_clips = math.ceil(duration / 6.0)\n        bins = [\"\"] * num_clips\n        all_words = []\n        \n        INDIC_LANGS = {'hi', 'bn', 'gu', 'kn', 'ml', 'mr', 'pa', 'ta', 'te', 'ur', 'sd', 'ne'}\n        detected_lang = raw_result.get('language', 'en')\n        should_transliterate = detected_lang in INDIC_LANGS\n        \n        for segment in raw_result['segments']:\n            if 'words' in segment:\n                for w in segment['words']:\n                    w_text = unidecode(w['word']) if should_transliterate else w['word']\n                    all_words.append({'word': w_text, 'start': w['start']})\n        \n        if all_words:\n            for w in all_words:\n                start = w['start']\n                idx = int(start // 6)\n                if idx < num_clips:\n                    bins[idx] += w['word'].strip() + \" \"\n        else:\n            for segment in raw_result['segments']:\n                start = segment['start']\n                idx = int(start // 6)\n                txt = segment['text'].strip()\n                if should_transliterate:\n                    txt = unidecode(txt)\n                if idx < num_clips:\n                    bins[idx] += txt + \" \"\n        \n        lines = []\n        for i in range(num_clips):\n            start_str = format_time_ref(i * 6)\n            end_str = format_time_ref((i + 1) * 6)\n            text_content = bins[i].strip() if bins[i].strip() else \"[No speech]\"\n            lines.append(f\"[{i+1}] ({start_str} - {end_str})\")\n            lines.append(f\"Text: {text_content}\")\n            lines.append(\"\")\n            lines.append(\"-\" * 20)\n            lines.append(\"\")\n        \n        return \"\\n\".join(lines)\n    except Exception as e:\n        print(f\"âŒ Prompts generation error: {e}\")\n        return None\n\ndef create_subtitles_ass(raw_result):\n    try:\n        from unidecode import unidecode\n        INDIC_LANGS = {'hi', 'bn', 'gu', 'kn', 'ml', 'mr', 'pa', 'ta', 'te', 'ur', 'sd', 'ne'}\n        detected_lang = raw_result.get('language', 'en')\n        should_transliterate = detected_lang in INDIC_LANGS\n        \n        ass_lines = [\n            \"[Script Info]\",\n            \"Title: Generated Subtitles\",\n            \"ScriptType: v4.00+\",\n            \"WrapStyle: 0\",\n            \"ScaledBorderAndShadow: yes\",\n            \"YCbCr Matrix: None\",\n            \"\",\n            \"[V4+ Styles]\",\n            \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\",\n            \"Style: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1\",\n            \"\",\n            \"[Events]\",\n            \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\",\n            \"\"\n        ]\n        \n        def format_ass_time(seconds):\n            h = int(seconds // 3600)\n            m = int((seconds % 3600) // 60)\n            s = int(seconds % 60)\n            cs = int((seconds % 1) * 100)\n            return f\"{h}:{m:02d}:{s:02d}.{cs:02d}\"\n        \n        for segment in raw_result['segments']:\n            start_time = format_ass_time(segment['start'])\n            end_time = format_ass_time(segment['end'])\n            text = segment['text'].strip()\n            \n            if should_transliterate:\n                text = unidecode(text)\n            \n            text = text.replace('\\\\', '\\\\\\\\').replace('\\n', '\\\\N')\n            ass_lines.append(f\"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}\")\n        \n        return \"\\n\".join(ass_lines)\n    except Exception as e:\n        print(f\"âŒ Subtitles generation error: {e}\")\n        return None\n\ndef transcribe_audio_on_gpu(audio_path):\n    try:\n        print(f\"ğŸ™ï¸ Transcribing with Whisper (GPU)...\")\n        result = WHISPER_MODEL.transcribe(audio_path, language=None, word_timestamps=True, verbose=False)\n        print(f\"âœ… Transcription complete: {len(result['segments'])} segments\")\n        return result\n    except Exception as e:\n        print(f\"âŒ Transcription error: {e}\")\n        return None\n\ndef process_transcription_job(job_key, job_data):\n    try:\n        job = json.loads(job_data) if isinstance(job_data, str) else job_data\n        job_id = job['job_id']\n        audio_r2_key = job['audio_r2_key']\n        \n        print(f\"\\nğŸ™ï¸ [TRANSCRIPTION] Processing: {job_id}\")\n        local_audio = f\"/tmp/audio_{job_id}.mp3\"\n        print(f\"   â¬‡ï¸ Downloading audio from R2...\")\n        s3_client.download_file(R2_BUCKET_NAME, audio_r2_key, local_audio)\n        \n        from moviepy.editor import AudioFileClip\n        clip = AudioFileClip(local_audio)\n        duration = clip.duration\n        clip.close()\n        \n        print(f\"   ğŸ™ï¸ Transcribing on GPU...\")\n        start_time = time.time()\n        result = transcribe_audio_on_gpu(local_audio)\n        \n        if not result:\n            db.reference(f'/transcriptions/failed/{job_id}').set({\n                'error': 'Transcription failed',\n                'timestamp': time.time()\n            })\n            db.reference(job_key).delete()\n            os.remove(local_audio)\n            return False\n        \n        transcribe_time = time.time() - start_time\n        \n        print(f\"   ğŸ“ Generating prompts TXT...\")\n        prompts_txt = create_prompts_txt(result, duration)\n        \n        print(f\"   ğŸ“„ Generating subtitles ASS...\")\n        subtitles_ass = create_subtitles_ass(result)\n        \n        result_json = json.dumps(result)\n        result_r2_key = f\"transcriptions/{job_id}.json\"\n        prompts_r2_key = f\"transcriptions/{job_id}_prompts.txt\"\n        subtitles_r2_key = f\"transcriptions/{job_id}_subtitles.ass\"\n        \n        print(f\"   â¬†ï¸ Uploading to R2...\")\n        s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=result_r2_key, Body=result_json.encode('utf-8'), ContentType='application/json')\n        s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=prompts_r2_key, Body=prompts_txt.encode('utf-8'), ContentType='text/plain')\n        s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=subtitles_r2_key, Body=subtitles_ass.encode('utf-8'), ContentType='text/plain')\n        \n        completion_data = {\n            \"transcription_r2_key\": result_r2_key,\n            \"prompts_r2_key\": prompts_r2_key,\n            \"subtitles_r2_key\": subtitles_r2_key,\n            \"duration\": transcribe_time,\n            \"audio_duration\": duration,\n            \"segments\": len(result['segments']),\n            \"job_id\": job_id,\n            \"server_id\": SERVER_ID\n        }\n        \n        db.reference(f'/transcriptions/completed/{job_id}').set(completion_data)\n        db.reference(f'/notifications/transcriptions/{job_id}').set(completion_data)\n        \n        db.reference(job_key).delete()\n        os.remove(local_audio)\n        print(f\"âœ… [TRANSCRIPTION] Done! â±ï¸ {transcribe_time:.1f}s\")\n        return True\n        \n    except Exception as e:\n        print(f\"âŒ [TRANSCRIPTION] Failed: {e}\")\n        db.reference(f'/transcriptions/failed/{job_id}').set({\n            'error': str(e),\n            'timestamp': time.time()\n        })\n        try:\n            db.reference(job_key).delete()\n        except:\n            pass\n        return False\n\n# ------------------------------------------\n# VIDEO GENERATION\n# ------------------------------------------\nSTEPS = 5\nGUIDANCE_SCALE = 2.0\n\nGPU_COUNT = torch.cuda.device_count()\n\ndef upload_to_r2(video_bytes, job_id, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            video_key = f\"videos/single/{job_id}.mp4\"\n            s3_client.put_object(Bucket=R2_BUCKET_NAME, Key=video_key, Body=video_bytes, ContentType='video/mp4')\n            url = s3_client.generate_presigned_url('get_object', Params={'Bucket': R2_BUCKET_NAME, 'Key': video_key}, ExpiresIn=604800)\n            return url\n        except Exception as e:\n            if attempt < max_retries - 1:\n                time.sleep(2 ** attempt)\n    return None\n\ndef image_to_video_clip(image, target_width, target_height, subtitle_path=None):\n    unique_id = str(uuid.uuid4())\n    img_path = f\"temp_{unique_id}.png\"\n    vid_path = f\"output_{unique_id}.mp4\"\n\n    try:\n        image.save(img_path)\n        w = (int(target_width) // 2) * 2\n        h = (int(target_height) // 2) * 2\n        \n        zoom_curve = \"1.1+0.1*cos(2*PI*on/180)\"\n        filter_chain = (\n            f\"scale={w}:{h}:flags=lanczos,\"\n            f\"zoompan=z='{zoom_curve}':d=180:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)':s={w}x{h},\"\n            f\"vignette=PI/6\"\n        )\n        \n        if subtitle_path and os.path.exists(subtitle_path):\n            abs_sub = os.path.abspath(subtitle_path).replace('\\\\', '/').replace(':', '\\\\:')\n            abs_fonts = os.path.abspath(FONT_DIR).replace('\\\\', '/').replace(':', '\\\\:')\n            filter_chain += f\",subtitles='{abs_sub}':fontsdir='{abs_fonts}'\"\n        \n        filter_chain += \",fps=30\"\n        \n        cmd = [\n            \"ffmpeg\", \"-y\", \"-loop\", \"1\", \"-i\", img_path, \"-t\", \"6\",\n            \"-vf\", filter_chain,\n            \"-c:v\", \"libx264\",\n            \"-preset\", \"veryfast\",\n            \"-crf\", \"28\",\n            \"-maxrate\", \"2M\",\n            \"-bufsize\", \"4M\",\n            \"-pix_fmt\", \"yuv420p\",\n            \"-threads\", \"8\",\n            vid_path\n        ]\n\n        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n        \n        if os.path.exists(vid_path):\n            with open(vid_path, \"rb\") as f:\n                return f.read()\n        return None\n    except Exception as e:\n        print(f\"Video generation error: {e}\")\n        return None\n    finally:\n        if os.path.exists(img_path): os.remove(img_path)\n        if os.path.exists(vid_path): os.remove(vid_path)\n\ndef load_engine(device_id):\n    print(f\"â³ Loading SDXL on GPU {device_id}...\")\n    pipe = StableDiffusionXLPipeline.from_pretrained(\n        \"SG161222/RealVisXL_V4.0_Lightning\",\n        torch_dtype=torch.float16,\n        variant=\"fp16\"\n    ).to(f\"cuda:{device_id}\")\n    \n    pipe.unet.to(memory_format=torch.channels_last)\n    try:\n        pipe.enable_xformers_memory_efficient_attention()\n    except: pass\n    \n    pipe.vae = AutoencoderKL.from_pretrained(\n        \"madebyollin/sdxl-vae-fp16-fix\",\n        torch_dtype=torch.float16\n    ).to(f\"cuda:{device_id}\")\n\n    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n    pipe.set_progress_bar_config(disable=True)\n    return pipe\n\npipelines = []\nif GPU_COUNT > 0:\n    for i in range(GPU_COUNT):\n        pipelines.append(load_engine(i))\n\ndef get_safe_resolution(aspect_ratio_name):\n    if aspect_ratio_name == \"16:9\": return (1152, 640, 1920, 1080)\n    elif aspect_ratio_name == \"9:16\": return (640, 1152, 1080, 1920)\n    elif aspect_ratio_name == \"4:5\": return (896, 1088, 1080, 1350)\n    elif aspect_ratio_name == \"16:7\": return (1152, 512, 1920, 840)\n    else: return (1024, 1024, 1024, 1024)\n\ndef process_single_job(job_data, pipeline, gpu_id):\n    \"\"\"Process a single video generation job\"\"\"\n    job_id = job_data['job_id']\n    prompt = job_data['prompt']\n    ratio = job_data['ratio']\n    subtitle_data = job_data.get('subtitle_data', [])\n    \n    print(f\"ğŸ¬ [{SERVER_ID}/GPU{gpu_id}] Starting: {job_id}\")\n    \n    start_time = time.time()\n    ai_w, ai_h, final_w, final_h = get_safe_resolution(ratio)\n    \n    # Generate image\n    neg = \"text, watermark, signature, logo, writing, letters, font, typography, bad anatomy, bad hands, missing fingers, extra fingers, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, three crus, fused feet, fused thigh, extra crus, ugly, gross, sloppy, messy, blurry, low quality, duplicate, distortion, mutation, double head\"\n    \n    image = pipeline(\n        prompt,\n        num_inference_steps=STEPS,\n        guidance_scale=GUIDANCE_SCALE,\n        width=ai_w,\n        height=ai_h,\n        negative_prompt=neg\n    ).images[0]\n    \n    # Generate subtitle file if needed\n    subtitle_path = None\n    if subtitle_data:\n        try:\n            unique_sub_id = str(uuid.uuid4())\n            temp_ass_path = f\"temp_{unique_sub_id}.ass\"\n            success = generate_clip_ass_subtitles(subtitle_data, final_w, final_h, temp_ass_path)\n            if success:\n                subtitle_path = temp_ass_path\n        except Exception as e:\n            print(f\"Subtitle gen failed: {e}\")\n    \n    # Render video\n    video_bytes = image_to_video_clip(image, target_width=final_w, target_height=final_h, subtitle_path=subtitle_path)\n    \n    if subtitle_path and os.path.exists(subtitle_path):\n        os.remove(subtitle_path)\n    \n    if video_bytes:\n        size_mb = len(video_bytes) / (1024 * 1024)\n        r2_url = upload_to_r2(video_bytes, job_id)\n        gen_time = time.time() - start_time\n        \n        if r2_url:\n            result_data = {\n                \"r2_url\": r2_url,\n                \"time\": gen_time,\n                \"size_mb\": size_mb,\n                \"job_id\": job_id,\n                \"server_id\": SERVER_ID,\n                \"gpu_id\": gpu_id\n            }\n            \n            db.reference(f'/servers/{SERVER_ID}/completed/{job_id}').set(result_data)\n            db.reference(f'/notifications/videos/{job_id}').set(result_data)\n            \n            print(f\"âœ… [{SERVER_ID}/GPU{gpu_id}] Done! â±ï¸ {gen_time:.1f}s | ğŸ’¾ {size_mb:.2f}MB\")\n            return True\n        else:\n            db.reference(f'/servers/{SERVER_ID}/failed/{job_id}').set({\n                'error': 'Upload failed',\n                'timestamp': time.time()\n            })\n    else:\n        db.reference(f'/servers/{SERVER_ID}/failed/{job_id}').set({\n            'error': 'Video generation failed',\n            'timestamp': time.time()\n        })\n    \n    return False\n\n# ============================================================================\n# PARALLEL GPU WORKER - EACH GPU RUNS INDEPENDENTLY\n# ============================================================================\ndef gpu_worker_loop(gpu_id, pipeline):\n    \"\"\"\n    Each GPU runs this loop independently in parallel\n    Both GPUs continuously fetch and process jobs\n    \"\"\"\n    print(f\"ğŸš€ [{SERVER_ID}] GPU{gpu_id} Worker Started\")\n    \n    while True:\n        try:\n            # Fetch job from Firebase queue\n            queue_ref = db.reference(f'/servers/{SERVER_ID}/job_queue')\n            jobs = queue_ref.get()\n            \n            if jobs and isinstance(jobs, dict):\n                # Get first available job\n                job_key = next(iter(jobs.keys()))\n                job_data = jobs[job_key]\n                \n                # Atomic: Delete job from queue immediately (prevent other GPUs from taking it)\n                queue_ref.child(job_key).delete()\n                \n                # Process the job on this GPU\n                process_single_job(job_data, pipeline, gpu_id)\n            else:\n                # No jobs available, wait a bit\n                time.sleep(0.5)\n            \n        except Exception as e:\n            print(f\"âŒ [{SERVER_ID}] GPU{gpu_id} Error: {e}\")\n            time.sleep(2)\n\n# ------------------------------------------\n# MAIN LOOP - START PARALLEL GPU WORKERS\n# ------------------------------------------\ndef main():\n    print(\"\\n\" + \"=\"*70)\n    print(f\"ğŸš€ GPU SERVER: {SERVER_ID} (DATASET AUTO-LOADER)\")\n    print(\"=\"*70)\n    print(f\"âœ… GPUs: {GPU_COUNT}\")\n    print(f\"âœ… Steps: {STEPS}\")\n    print(f\"âœ… Firebase: {FIREBASE_DATABASE_URL}\")\n    print(f\"âœ… Path: /servers/{SERVER_ID}\")\n    print(f\"âœ… Credentials: Loaded from dataset (auto-failover enabled)\")\n    print(f\"âœ… Mode: PARALLEL (Each GPU processes independently)\")\n    print(\"=\"*70 + \"\\n\")\n    \n    # Start a worker thread for each GPU\n    gpu_threads = []\n    for gpu_id in range(GPU_COUNT):\n        t = threading.Thread(\n            target=gpu_worker_loop,\n            args=(gpu_id, pipelines[gpu_id]),\n            daemon=True\n        )\n        t.start()\n        gpu_threads.append(t)\n    \n    print(f\"ğŸ”¥ {GPU_COUNT} GPU Workers Running in Parallel!\\n\")\n    \n    # Main thread handles transcription (priority) and shutdown\n    while True:\n        # Check shutdown time (3:30 PM and 11:00 PM IST)\n        now_utc = datetime.now(timezone.utc)\n        now_ist = now_utc + timedelta(hours=5, minutes=30)\n        \n        is_time1 = (now_ist.hour == 15 and now_ist.minute == 30)\n        is_time2 = (now_ist.hour == 23 and now_ist.minute == 0)\n        \n        if is_time1 or is_time2:\n            print(f\"\\nğŸ›‘ [{SERVER_ID}] Scheduled Shutdown: {now_ist.strftime('%I:%M %p')} IST\")\n            sys.exit(0)\n\n        try:\n            # Handle transcription jobs (priority over video generation)\n            transcribe_ref = db.reference(f'/transcriptions/pending')\n            transcribe_jobs = transcribe_ref.get()\n            \n            if transcribe_jobs and isinstance(transcribe_jobs, dict):\n                job_key = next(iter(transcribe_jobs.keys()))\n                job_data = transcribe_jobs[job_key]\n                print(f\"\\nğŸ”¥ [{SERVER_ID}] PRIORITY: Transcription job found\")\n                process_transcription_job(f'/transcriptions/pending/{job_key}', job_data)\n            \n            time.sleep(1)\n            \n        except KeyboardInterrupt:\n            print(f\"\\nğŸ›‘ [{SERVER_ID}] Shutting down...\")\n            break\n        except Exception as e:\n            print(f\"âŒ [{SERVER_ID}] Main loop error: {e}\")\n            time.sleep(5)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-05T02:48:23.841452Z","iopub.execute_input":"2026-01-05T02:48:23.842261Z"}},"outputs":[{"name":"stdout","text":"â¬‡ï¸ Installing openai-whisper...\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 803.2/803.2 kB 13.8 MB/s eta 0:00:00\nâ¬‡ï¸ Installing unidecode...\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 235.8/235.8 kB 6.2 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"2026-01-05 02:48:59.985131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767581340.197964      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767581340.263256      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767581340.771208      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767581340.771257      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767581340.771260      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767581340.771263      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nğŸš€ [server_1] FIREBASE INITIALIZATION STARTING...\n======================================================================\n\n\n======================================================================\nğŸ” [server_1] LOADING FIREBASE CREDENTIALS FROM DATASET\n======================================================================\nğŸ“ Dataset: firebase-credentials\nğŸ“‚ Path: /kaggle/input/firebase-credentials\n\nâœ… Found 4 credential file(s):\n\n  âœ… kaggle-a46bc-566779df174a.json\n     ğŸ“Œ Project: kaggle-a46bc\n  âœ… kaggle-a46bc-7716cbe39f8e.json\n     ğŸ“Œ Project: kaggle-a46bc\n  âœ… kaggle-a46bc-c137981f3dff.json\n     ğŸ“Œ Project: kaggle-a46bc\n  âœ… kaggle-a46bc-edb16e7c97f4.json\n     ğŸ“Œ Project: kaggle-a46bc\n\n======================================================================\nğŸ“Š Total valid credentials: 4\n======================================================================\n\n======================================================================\nğŸ”§ [server_1] CONNECTING TO FIREBASE (AUTO-FAILOVER)\n======================================================================\n\n[Attempt 1/4] Trying: kaggle-a46bc-566779df174a.json\n  ğŸ“Œ Project: kaggle-a46bc\n  âœ… CONNECTION SUCCESSFUL!\n  ğŸ‰ Using credential: kaggle-a46bc-566779df174a.json\n  ğŸŒ Database: https://kaggle-a46bc-default-rtdb.firebaseio.com\n\n======================================================================\nâœ… [server_1] FIREBASE READY!\n======================================================================\n\nâ¬‡ï¸ Setting up fonts...\nğŸ”§ Setting up R2...\nâœ… R2 ready\nğŸ’“ Heartbeat started for server_1...\nâ³ Loading Whisper Model on GPU...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:01<00:00, 74.5MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… Whisper model loaded\nâ³ Loading SDXL on GPU 0...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/577 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e9aa02ffad34c05af386fc0d93390e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a07b47192fe4a4b8fe18699c41fce48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/560 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef91f93d3bb4263b9c3bc3eec02a6f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43d77d6692704267aba4595451749497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11e5069c94e4966afbe40671cdcb423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"828f9ca2542c4ec39f0c688f4bc84d27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder_2/model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f56c4f54f92f4ab7a7ab7eb3bad1cb5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfdf4631562e43c4b7b74e17e22b3ac3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b122d682c84ff0a286afc58c66a077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecdcae3064b643c98d24018c021e7709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d6a8c4d14d413cbed0b9dac8c22d92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"371c5ee1fe25407ab1fb7b4689f80438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"468dc5a24df34b4aa303e57a41f5f57a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd16b66194104adea1d7e8291d0df009"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/602 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3234953c90c41a1a00c73cf7457a02e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/diffusion_pytorch_model.fp16.safete(â€¦):   0%|          | 0.00/5.14G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cdca2a9e13e44f0974d48cd7ae2dafd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/diffusion_pytorch_model.fp16.safeten(â€¦):   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"901691e2f409477dbdb87a21487a7cc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e55284ade18d46bb911da01b257dd99f"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b22ae236b9d44bdb85949a5fee84ee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff1870ba34149649bd7c12388d91626"}},"metadata":{}},{"name":"stdout","text":"â³ Loading SDXL on GPU 1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb669ad2ca140fb81583f49f091216b"}},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nğŸš€ GPU SERVER: server_1 (DATASET AUTO-LOADER)\n======================================================================\nâœ… GPUs: 2\nâœ… Steps: 5\nâœ… Firebase: https://kaggle-a46bc-default-rtdb.firebaseio.com\nâœ… Path: /servers/server_1\nâœ… Credentials: Loaded from dataset (auto-failover enabled)\nâœ… Mode: PARALLEL (Each GPU processes independently)\n======================================================================\n\nğŸš€ [server_1] GPU0 Worker Started\nğŸš€ [server_1] GPU1 Worker Started\nğŸ”¥ 2 GPU Workers Running in Parallel!\n\nğŸ¬ [server_1/GPU1] Starting: job_1767581446_19331_2\nğŸ¬ [server_1/GPU0] Starting: job_1767581446_59632_5\nâœ… [server_1/GPU1] Done! â±ï¸ 14.9s | ğŸ’¾ 0.48MB\nâœ… [server_1/GPU0] Done! â±ï¸ 15.2s | ğŸ’¾ 0.36MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581463_50946_8\nğŸ¬ [server_1/GPU0] Starting: job_1767581464_67909_11\nâœ… [server_1/GPU1] Done! â±ï¸ 12.0s | ğŸ’¾ 0.49MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581474_56872_14\nâœ… [server_1/GPU0] Done! â±ï¸ 12.7s | ğŸ’¾ 0.35MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581479_34404_17\nâœ… [server_1/GPU1] Done! â±ï¸ 10.8s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581488_15081_20\nâœ… [server_1/GPU0] Done! â±ï¸ 12.0s | ğŸ’¾ 0.31MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581493_94167_23\nâœ… [server_1/GPU1] Done! â±ï¸ 11.1s | ğŸ’¾ 0.49MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581497_66610_26\nâœ… [server_1/GPU0] Done! â±ï¸ 11.9s | ğŸ’¾ 0.44MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581505_90128_29\nâœ… [server_1/GPU1] Done! â±ï¸ 11.0s | ğŸ’¾ 0.47MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581509_26372_32\nâœ… [server_1/GPU0] Done! â±ï¸ 11.4s | ğŸ’¾ 0.43MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581518_85914_35\nâœ… [server_1/GPU1] Done! â±ï¸ 11.1s | ğŸ’¾ 0.44MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581522_43552_38\nâœ… [server_1/GPU0] Done! â±ï¸ 11.2s | ğŸ’¾ 0.52MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581530_62254_41\nâœ… [server_1/GPU1] Done! â±ï¸ 11.1s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581534_13024_44\nâœ… [server_1/GPU0] Done! â±ï¸ 11.9s | ğŸ’¾ 0.34MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581543_38183_47\nâœ… [server_1/GPU1] Done! â±ï¸ 11.9s | ğŸ’¾ 0.55MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581547_21802_50\nâœ… [server_1/GPU0] Done! â±ï¸ 12.1s | ğŸ’¾ 0.33MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581554_26595_53\nâœ… [server_1/GPU1] Done! â±ï¸ 12.2s | ğŸ’¾ 0.52MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581559_22677_56\nâœ… [server_1/GPU0] Done! â±ï¸ 11.0s | ğŸ’¾ 0.47MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581567_82328_59\nâœ… [server_1/GPU1] Done! â±ï¸ 11.9s | ğŸ’¾ 0.36MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581573_62950_62\nâœ… [server_1/GPU0] Done! â±ï¸ 10.5s | ğŸ’¾ 0.53MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581579_12642_65\nâœ… [server_1/GPU1] Done! â±ï¸ 11.0s | ğŸ’¾ 0.60MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581586_22961_68\nâœ… [server_1/GPU0] Done! â±ï¸ 10.0s | ğŸ’¾ 0.35MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581592_35590_71\nâœ… [server_1/GPU1] Done! â±ï¸ 10.8s | ğŸ’¾ 0.42MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581599_22393_74\nâœ… [server_1/GPU0] Done! â±ï¸ 10.9s | ğŸ’¾ 0.63MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581605_14580_77\nâœ… [server_1/GPU1] Done! â±ï¸ 11.7s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581613_57591_80\nâœ… [server_1/GPU0] Done! â±ï¸ 11.4s | ğŸ’¾ 0.42MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581618_27320_83\nâœ… [server_1/GPU1] Done! â±ï¸ 11.5s | ğŸ’¾ 0.43MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581627_65566_86\nâœ… [server_1/GPU0] Done! â±ï¸ 11.4s | ğŸ’¾ 0.66MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581630_42882_89\nâœ… [server_1/GPU1] Done! â±ï¸ 12.1s | ğŸ’¾ 0.34MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581641_29154_92\nâœ… [server_1/GPU0] Done! â±ï¸ 11.5s | ğŸ’¾ 0.46MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581644_91677_95\nâœ… [server_1/GPU1] Done! â±ï¸ 12.7s | ğŸ’¾ 0.53MB\nâœ… [server_1/GPU0] Done! â±ï¸ 11.6s | ğŸ’¾ 0.42MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581656_25727_98\nğŸ¬ [server_1/GPU0] Starting: job_1767581658_77940_101\nâœ… [server_1/GPU1] Done! â±ï¸ 11.9s | ğŸ’¾ 0.55MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581670_21387_104\nâœ… [server_1/GPU0] Done! â±ï¸ 12.1s | ğŸ’¾ 0.49MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581672_47287_107\nâœ… [server_1/GPU1] Done! â±ï¸ 12.3s | ğŸ’¾ 0.35MB\nğŸ¬ [server_1/GPU1] Starting: job_1767581684_21684_110\nâœ… [server_1/GPU0] Done! â±ï¸ 12.7s | ğŸ’¾ 0.49MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581687_69664_113\nâœ… [server_1/GPU1] Done! â±ï¸ 12.7s | ğŸ’¾ 0.49MB\nâœ… [server_1/GPU0] Done! â±ï¸ 12.1s | ğŸ’¾ 0.70MB\nğŸ¬ [server_1/GPU0] Starting: job_1767581717_87079_2\nâœ… [server_1/GPU0] Done! â±ï¸ 8.9s | ğŸ’¾ 0.28MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583038_86548_0\nğŸ¬ [server_1/GPU0] Starting: job_1767583038_86548_0\nâœ… [server_1/GPU1] Done! â±ï¸ 12.5s | ğŸ’¾ 0.29MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583038_21808_3\nâœ… [server_1/GPU0] Done! â±ï¸ 12.9s | ğŸ’¾ 0.37MB\nâœ… [server_1/GPU1] Done! â±ï¸ 10.2s | ğŸ’¾ 0.49MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583413_64584_2\nğŸ¬ [server_1/GPU0] Starting: job_1767583413_64584_2\nâœ… [server_1/GPU1] Done! â±ï¸ 12.2s | ğŸ’¾ 0.42MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583413_82930_5\nâœ… [server_1/GPU0] Done! â±ï¸ 12.4s | ğŸ’¾ 0.39MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583427_87434_8\nâœ… [server_1/GPU1] Done! â±ï¸ 11.5s | ğŸ’¾ 0.39MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583430_36690_11\nâœ… [server_1/GPU0] Done! â±ï¸ 11.7s | ğŸ’¾ 0.32MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583442_11863_14\nâœ… [server_1/GPU1] Done! â±ï¸ 10.9s | ğŸ’¾ 0.36MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583445_23041_17\nâœ… [server_1/GPU0] Done! â±ï¸ 10.9s | ğŸ’¾ 0.34MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583456_18310_20\nâœ… [server_1/GPU1] Done! â±ï¸ 10.8s | ğŸ’¾ 0.49MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583458_83923_23\nâœ… [server_1/GPU0] Done! â±ï¸ 12.1s | ğŸ’¾ 0.64MB\nâœ… [server_1/GPU1] Done! â±ï¸ 11.8s | ğŸ’¾ 0.40MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583471_87380_26\nğŸ¬ [server_1/GPU0] Starting: job_1767583473_37859_29\nâœ… [server_1/GPU1] Done! â±ï¸ 11.8s | ğŸ’¾ 0.37MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583482_30257_32\nâœ… [server_1/GPU0] Done! â±ï¸ 12.7s | ğŸ’¾ 0.45MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583487_86301_35\nâœ… [server_1/GPU1] Done! â±ï¸ 11.3s | ğŸ’¾ 0.46MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583496_16944_38\nâœ… [server_1/GPU0] Done! â±ï¸ 10.5s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583500_94961_41\nâœ… [server_1/GPU1] Done! â±ï¸ 11.9s | ğŸ’¾ 0.57MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583510_71082_44\nâœ… [server_1/GPU0] Done! â±ï¸ 11.7s | ğŸ’¾ 0.48MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583513_63118_47\nâœ… [server_1/GPU1] Done! â±ï¸ 11.9s | ğŸ’¾ 0.61MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583521_69706_50\nâœ… [server_1/GPU0] Done! â±ï¸ 12.1s | ğŸ’¾ 0.38MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583526_96283_53\nâœ… [server_1/GPU1] Done! â±ï¸ 12.1s | ğŸ’¾ 0.46MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583532_49831_56\nâœ… [server_1/GPU0] Done! â±ï¸ 11.9s | ğŸ’¾ 0.39MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583540_73811_59\nâœ… [server_1/GPU1] Done! â±ï¸ 10.7s | ğŸ’¾ 0.28MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583545_77417_62\nâœ… [server_1/GPU0] Done! â±ï¸ 11.9s | ğŸ’¾ 0.55MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583554_33588_65\nâœ… [server_1/GPU1] Done! â±ï¸ 11.0s | ğŸ’¾ 0.62MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583558_80857_68\nâœ… [server_1/GPU0] Done! â±ï¸ 11.2s | ğŸ’¾ 0.47MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583567_23147_71\nâœ… [server_1/GPU1] Done! â±ï¸ 10.6s | ğŸ’¾ 0.38MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583572_52476_74\nâœ… [server_1/GPU0] Done! â±ï¸ 12.6s | ğŸ’¾ 0.70MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583580_29244_77\nâœ… [server_1/GPU1] Done! â±ï¸ 11.6s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583585_29917_80\nâœ… [server_1/GPU0] Done! â±ï¸ 11.4s | ğŸ’¾ 0.39MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583594_77913_83\nâœ… [server_1/GPU1] Done! â±ï¸ 11.4s | ğŸ’¾ 0.47MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583599_88170_86\nâœ… [server_1/GPU0] Done! â±ï¸ 11.1s | ğŸ’¾ 0.61MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583608_84935_89\nâœ… [server_1/GPU1] Done! â±ï¸ 11.4s | ğŸ’¾ 0.38MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583611_69402_92\nâœ… [server_1/GPU0] Done! â±ï¸ 12.6s | ğŸ’¾ 0.47MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583623_66065_95\nâœ… [server_1/GPU1] Done! â±ï¸ 11.8s | ğŸ’¾ 0.53MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583625_39689_98\nâœ… [server_1/GPU0] Done! â±ï¸ 12.0s | ğŸ’¾ 0.37MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583636_51985_101\nâœ… [server_1/GPU1] Done! â±ï¸ 11.6s | ğŸ’¾ 0.41MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583638_20329_104\nâœ… [server_1/GPU0] Done! â±ï¸ 12.7s | ğŸ’¾ 0.44MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583651_38930_107\nâœ… [server_1/GPU1] Done! â±ï¸ 12.8s | ğŸ’¾ 0.58MB\nğŸ¬ [server_1/GPU1] Starting: job_1767583653_17941_110\nâœ… [server_1/GPU0] Done! â±ï¸ 12.4s | ğŸ’¾ 0.56MB\nğŸ¬ [server_1/GPU0] Starting: job_1767583664_20801_113\nâœ… [server_1/GPU1] Done! â±ï¸ 12.3s | ğŸ’¾ 0.23MB\nâœ… [server_1/GPU0] Done! â±ï¸ 10.0s | ğŸ’¾ 0.63MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584367_16314_1\nğŸ¬ [server_1/GPU0] Starting: job_1767584367_24861_7\nâœ… [server_1/GPU0] Done! â±ï¸ 10.4s | ğŸ’¾ 0.34MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584367_26079_4\nâœ… [server_1/GPU1] Done! â±ï¸ 10.6s | ğŸ’¾ 0.29MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584380_74787_10\nâœ… [server_1/GPU0] Done! â±ï¸ 9.6s | ğŸ’¾ 0.32MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584381_75803_13\nâœ… [server_1/GPU1] Done! â±ï¸ 9.8s | ğŸ’¾ 0.23MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584391_66492_16\nâœ… [server_1/GPU0] Done! â±ï¸ 9.4s | ğŸ’¾ 0.21MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584393_55601_19\nâœ… [server_1/GPU1] Done! â±ï¸ 10.6s | ğŸ’¾ 0.26MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584403_42845_22\nâœ… [server_1/GPU0] Done! â±ï¸ 9.7s | ğŸ’¾ 0.32MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584404_44424_25\nâœ… [server_1/GPU1] Done! â±ï¸ 9.8s | ğŸ’¾ 0.28MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584413_91983_28\nâœ… [server_1/GPU0] Done! â±ï¸ 10.2s | ğŸ’¾ 0.24MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584415_83227_31\nâœ… [server_1/GPU1] Done! â±ï¸ 9.3s | ğŸ’¾ 0.25MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584423_35355_34\nâœ… [server_1/GPU0] Done! â±ï¸ 9.6s | ğŸ’¾ 0.23MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584426_18302_37\nâœ… [server_1/GPU1] Done! â±ï¸ 9.4s | ğŸ’¾ 0.24MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584433_18737_40\nâœ… [server_1/GPU0] Done! â±ï¸ 9.8s | ğŸ’¾ 0.34MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584437_66178_43\nâœ… [server_1/GPU1] Done! â±ï¸ 9.5s | ğŸ’¾ 0.21MB\nâœ… [server_1/GPU0] Done! â±ï¸ 9.0s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584474_36113_0\nğŸ¬ [server_1/GPU0] Starting: job_1767584474_16374_3\nâœ… [server_1/GPU0] Done! â±ï¸ 12.8s | ğŸ’¾ 0.48MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584474_14893_6\nâœ… [server_1/GPU1] Done! â±ï¸ 13.0s | ğŸ’¾ 0.40MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584474_16374_3\nâœ… [server_1/GPU0] Done! â±ï¸ 12.5s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584474_36113_0\nâœ… [server_1/GPU1] Done! â±ï¸ 12.8s | ğŸ’¾ 0.50MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584474_16374_3\nâœ… [server_1/GPU0] Done! â±ï¸ 12.5s | ğŸ’¾ 0.43MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584474_36113_0\nâœ… [server_1/GPU1] Done! â±ï¸ 12.3s | ğŸ’¾ 0.55MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584501_33249_1\nâœ… [server_1/GPU0] Done! â±ï¸ 13.0s | ğŸ’¾ 0.46MB\nğŸ¬ [server_1/GPU0] Starting: job_1767584501_99692_4\nâœ… [server_1/GPU1] Done! â±ï¸ 11.7s | ğŸ’¾ 0.46MB\nğŸ¬ [server_1/GPU1] Starting: job_1767584501_43414_7\n","output_type":"stream"}],"execution_count":null}]}